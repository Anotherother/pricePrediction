{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.get_data as get_data\n",
    "import src.load_data as load\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "from keras.callbacks import History \n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "WINDOW = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape):\n",
    "    d = 0.2\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"normal\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"normal\",activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def next5minutePrediction(typeBlockchain, stock):    \n",
    "    \n",
    "    plot = True\n",
    "    plotHictory = True\n",
    "    interactiveGrapth = True\n",
    "    plotForTrain = False\n",
    "    \n",
    "    #df = get_data.get_data_frame(typeBlockchain, stock)\n",
    "    df = pd.read_csv('../../data/5_minutes_dump.csv')\n",
    "\n",
    "    df.columns = ['open', 'close','low', 'high', 'volume', 'date_time', 'ex', 'typeBlockchain']\n",
    "    df.index = df.date_time\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    all_df = df.copy()\n",
    "\n",
    "    x = all_df[['open', 'low', 'high', 'volume']].copy()\n",
    "    \n",
    "    y = all_df['close'].copy()\n",
    "    \n",
    "    x = pd.ewma(x,2)\n",
    "    y = pd.ewma(y,2)\n",
    "    \n",
    "    x[['open', 'low', 'high', 'volume']] = x_scaler.fit_transform(x)\n",
    "\n",
    "    y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    x['close'] = y\n",
    "    \n",
    "    #X_train, y_train = load.load_data(x, WINDOW, TrainTest = False)\n",
    "    X_train, y_train, X_test, y_test = load.load_data(x, WINDOW, train_size= 0.90, TrainTest = True)\n",
    "    \n",
    "    model = build_model(input_shape=(WINDOW, 5))\n",
    "    \n",
    "    print('START FIT MODEL...')\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    history = History()\n",
    "    history= model.fit(X_train, y_train, validation_data=(X_test, y_test),  batch_size=32, epochs=200,verbose=1,\n",
    "              callbacks=[history])\n",
    "    \n",
    "    #model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "    end = time.time()\n",
    "\n",
    "    print ('Learning time: ', end-start)\n",
    "    \n",
    "    today = time.strftime(\"_%d_%m_%Y\")\n",
    "    \n",
    "    pathModel = \"../../models/model_5fshort_\" + typeBlockchain + today +\".h5\"\n",
    "    save_model(model, pathModel)\n",
    "    #model = load_model(pathModel)\n",
    "    # one day prediction. get last batch known data (now we didnt need in y value and can predict it)    \n",
    "    lastbatch = np.array(x[-WINDOW:])\n",
    "    pred = model.predict([lastbatch.reshape(1,22, 5)])\n",
    "    pred =  np.array(y_scaler.inverse_transform(pred)) # predicted value\n",
    "\n",
    "    # now we make dataframe and create row names in date\n",
    "\n",
    "    splitStr = str(df.date_time[df.last_valid_index()]).split(' ')\n",
    "    lastDate =splitStr[0].split('-')\n",
    "    lastTime = splitStr[1].split(':')\n",
    "\n",
    "    predictionDate = datetime.datetime(int(lastDate[0]),int(lastDate[1]),int(lastDate[2]),\\\n",
    "                                    int(lastTime[0]), int(lastTime[1]))  + datetime.timedelta(minutes=5)\n",
    "\n",
    "    predictionDate = pd.date_range(predictionDate, periods=1)\n",
    "\n",
    "    prediction = pd.DataFrame(pred, columns=[\"predictionPrice\"], index = predictionDate.values)\n",
    "\n",
    "    print (prediction)\n",
    "\n",
    "    if plotForTrain:\n",
    "        \n",
    "        trainPredict = model.predict(X_train)\n",
    "        trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "        prices = df.close.values.astype('float32')\n",
    "        prices = prices.reshape(len(prices), 1)\n",
    "        trainPredictPlot = np.empty_like(prices)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "        Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.index).close\n",
    "        Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "        ActualValues = go.Scatter( x = df.date_time, y = Actual, name = 'ActualValues')\n",
    "        TrainingValues = go.Scatter( x = df.date_time, y = Training, name = 'TrainingValues')\n",
    "\n",
    "        iplot([ActualValues,TrainingValues])\n",
    "        plt.show()\n",
    "        \n",
    "    if plot:\n",
    "        trainPredict = model.predict(X_train)\n",
    "        testPredict = model.predict(X_test)\n",
    "\n",
    "        trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "        trainY = y_scaler.inverse_transform([y_train])\n",
    "\n",
    "        testPredict = y_scaler.inverse_transform(testPredict)\n",
    "        testY = y_scaler.inverse_transform([y_test])\n",
    "\n",
    "        trainScore = metrics.mean_squared_error(trainY[0], trainPredict[:,0]) ** .5\n",
    "        print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "        testScore = metrics.mean_squared_error(testY[0], testPredict[:,0]) ** .5\n",
    "        print('Test Score: %.2f RMSE' % (testScore))\n",
    "        prices = df.close.values.astype('float32')\n",
    "        prices = prices.reshape(len(prices), 1)\n",
    "        trainPredictPlot = np.empty_like(prices)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "\n",
    "        testPredictPlot = np.empty_like(prices)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[(len(prices) - testPredict.shape[0]):len(prices), :] = testPredict\n",
    "\n",
    "        plt.plot(pd.DataFrame(prices, columns=[\"close\"]).close, label='Actual')\n",
    "        plt.plot(pd.DataFrame(trainPredictPlot, columns=[\"close\"]).close, label='Training')\n",
    "        plt.plot(pd.DataFrame(testPredictPlot, columns=[\"close\"]).close, label='Testing')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "        interactiveGrapth = 1\n",
    "        if interactiveGrapth:\n",
    "\n",
    "            Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.index).close\n",
    "            Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "            Testing = pd.DataFrame(testPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "\n",
    "            Actual.to_csv('Actual.csv')\n",
    "            Training.to_csv('Training.csv')\n",
    "            Testing.to_csv('Testing.csv')\n",
    "\n",
    "            #ActualValues = go.Scatter( x = df.date_time, y = Actual, name = 'ActualValues')\n",
    "            #TrainingValues = go.Scatter( x = df.date_time, y = Training, name = 'TrainingValues')\n",
    "            #TestingValues = go.Scatter( x = df.date_time, y = Testing, name = 'PredictedValues')\n",
    "\n",
    "            #iplot([ActualValues,TrainingValues, TestingValues])\n",
    "            #plt.show()\n",
    "        if plotHictory:\n",
    "\n",
    "            plt.plot(history.history['loss'], label = 'TrainLoss')\n",
    "            plt.plot(history.history['val_loss'], label = 'TestLoss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning:\n",
      "\n",
      "pd.ewm_mean is deprecated for DataFrame and will be removed in a future version, replace with \n",
      "\tDataFrame.ewm(com=2,min_periods=0,adjust=True,ignore_na=False).mean()\n",
      "\n",
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning:\n",
      "\n",
      "pd.ewm_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.ewm(com=2,min_periods=0,adjust=True,ignore_na=False).mean()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START FIT MODEL...\n",
      "Train on 186081 samples, validate on 20676 samples\n",
      "Epoch 1/200\n",
      "186081/186081 [==============================] - 232s - loss: 1.3766e-04 - acc: 5.3740e-06 - val_loss: 0.0019 - val_acc: 4.8365e-05\n",
      "Epoch 2/200\n",
      "186081/186081 [==============================] - 232s - loss: 5.4492e-05 - acc: 5.3740e-06 - val_loss: 0.0041 - val_acc: 4.8365e-05\n",
      "Epoch 3/200\n",
      "186081/186081 [==============================] - 232s - loss: 3.8855e-05 - acc: 5.3740e-06 - val_loss: 0.0061 - val_acc: 4.8365e-05\n",
      "Epoch 4/200\n",
      "186081/186081 [==============================] - 232s - loss: 3.3424e-05 - acc: 5.3740e-06 - val_loss: 0.0089 - val_acc: 4.8365e-05\n",
      "Epoch 5/200\n",
      "186081/186081 [==============================] - 241s - loss: 2.6421e-05 - acc: 5.3740e-06 - val_loss: 0.0025 - val_acc: 4.8365e-05\n",
      "Epoch 6/200\n",
      "186081/186081 [==============================] - 258s - loss: 1.9460e-05 - acc: 5.3740e-06 - val_loss: 0.0037 - val_acc: 4.8365e-05\n",
      "Epoch 7/200\n",
      "186081/186081 [==============================] - 248s - loss: 1.6946e-05 - acc: 5.3740e-06 - val_loss: 0.0042 - val_acc: 4.8365e-05\n",
      "Epoch 8/200\n",
      "186081/186081 [==============================] - 263s - loss: 1.5547e-05 - acc: 5.3740e-06 - val_loss: 0.0173 - val_acc: 4.8365e-05\n",
      "Epoch 9/200\n",
      "186081/186081 [==============================] - 263s - loss: 1.4908e-05 - acc: 5.3740e-06 - val_loss: 0.0073 - val_acc: 4.8365e-05\n",
      "Epoch 10/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.3247e-05 - acc: 5.3740e-06 - val_loss: 0.0149 - val_acc: 4.8365e-05\n",
      "Epoch 11/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.2129e-05 - acc: 5.3740e-06 - val_loss: 0.0113 - val_acc: 4.8365e-05\n",
      "Epoch 12/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.1004e-05 - acc: 5.3740e-06 - val_loss: 0.0071 - val_acc: 4.8365e-05\n",
      "Epoch 13/200\n",
      "186081/186081 [==============================] - 234s - loss: 1.0148e-05 - acc: 5.3740e-06 - val_loss: 0.0121 - val_acc: 4.8365e-05\n",
      "Epoch 14/200\n",
      "186081/186081 [==============================] - 235s - loss: 9.8585e-06 - acc: 5.3740e-06 - val_loss: 0.0135 - val_acc: 4.8365e-05\n",
      "Epoch 15/200\n",
      "186081/186081 [==============================] - 236s - loss: 9.3775e-06 - acc: 5.3740e-06 - val_loss: 0.0106 - val_acc: 4.8365e-05\n",
      "Epoch 16/200\n",
      "186081/186081 [==============================] - 235s - loss: 8.9064e-06 - acc: 5.3740e-06 - val_loss: 0.0105 - val_acc: 4.8365e-05\n",
      "Epoch 17/200\n",
      "186081/186081 [==============================] - 234s - loss: 8.3041e-06 - acc: 5.3740e-06 - val_loss: 0.0106 - val_acc: 4.8365e-05\n",
      "Epoch 18/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.9790e-06 - acc: 5.3740e-06 - val_loss: 0.0108 - val_acc: 4.8365e-05\n",
      "Epoch 19/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.4972e-06 - acc: 5.3740e-06 - val_loss: 0.0107 - val_acc: 4.8365e-05\n",
      "Epoch 20/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.1531e-06 - acc: 5.3740e-06 - val_loss: 0.0120 - val_acc: 4.8365e-05\n",
      "Epoch 21/200\n",
      "186081/186081 [==============================] - 235s - loss: 6.9927e-06 - acc: 5.3740e-06 - val_loss: 0.0094 - val_acc: 4.8365e-05\n",
      "Epoch 22/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.6654e-06 - acc: 5.3740e-06 - val_loss: 0.0122 - val_acc: 4.8365e-05\n",
      "Epoch 23/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.5135e-06 - acc: 5.3740e-06 - val_loss: 0.0163 - val_acc: 4.8365e-05\n",
      "Epoch 24/200\n",
      "186081/186081 [==============================] - 236s - loss: 6.3315e-06 - acc: 5.3740e-06 - val_loss: 0.0143 - val_acc: 4.8365e-05\n",
      "Epoch 25/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.3030e-06 - acc: 5.3740e-06 - val_loss: 0.0183 - val_acc: 4.8365e-05\n",
      "Epoch 26/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.0133e-06 - acc: 5.3740e-06 - val_loss: 0.0168 - val_acc: 4.8365e-05\n",
      "Epoch 27/200\n",
      "173920/186081 [===========================>..] - ETA: 14s - loss: 5.8427e-06 - acc: 5.7498e-06"
     ]
    }
   ],
   "source": [
    "USDT_BTC = next5minutePrediction('USDT_BTC', 'poloniex' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
