{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.get_data as get_data\n",
    "import src.load_data as load\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "from keras.callbacks import History \n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "WINDOW = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape):\n",
    "    d = 0.2\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"normal\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"normal\",activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def next5minutePrediction(typeBlockchain, stock):    \n",
    "    \n",
    "    plot = True\n",
    "    plotHictory = True\n",
    "    interactiveGrapth = True\n",
    "    plotForTrain = False\n",
    "    \n",
    "    #df = get_data.get_data_frame(typeBlockchain, stock)\n",
    "    df = pd.read_csv('../../data/5_minutes_dump.csv')\n",
    "\n",
    "    df.columns = ['open', 'close','low', 'high', 'volume', 'date_time', 'ex', 'typeBlockchain']\n",
    "    df.index = df.date_time\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    x_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    all_df = df.copy()\n",
    "\n",
    "    x = all_df[['open', 'low', 'high', 'volume']].copy()\n",
    "    \n",
    "    y = all_df['close'].copy()\n",
    "    \n",
    "    x = pd.ewma(x,2)\n",
    "    y = pd.ewma(y,2)\n",
    "    \n",
    "    x[['open', 'low', 'high', 'volume']] = x_scaler.fit_transform(x)\n",
    "\n",
    "    y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    x['close'] = y\n",
    "    \n",
    "    #X_train, y_train = load.load_data(x, WINDOW, TrainTest = False)\n",
    "    X_train, y_train, X_test, y_test = load.load_data(x, WINDOW, train_size= 0.90, TrainTest = True)\n",
    "    \n",
    "    model = build_model(input_shape=(WINDOW, 5))\n",
    "    \n",
    "    print('START FIT MODEL...')\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    history = History()\n",
    "    history= model.fit(X_train, y_train, validation_data=(X_test, y_test),  batch_size=32, epochs=200,verbose=1,\n",
    "              callbacks=[history])\n",
    "    \n",
    "    #model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "    end = time.time()\n",
    "\n",
    "    print ('Learning time: ', end-start)\n",
    "    \n",
    "    today = time.strftime(\"_%d_%m_%Y\")\n",
    "    \n",
    "    pathModel = \"../../models/model_5fshort_\" + typeBlockchain + today +\".h5\"\n",
    "    save_model(model, pathModel)\n",
    "    #model = load_model(pathModel)\n",
    "    # one day prediction. get last batch known data (now we didnt need in y value and can predict it)    \n",
    "    lastbatch = np.array(x[-WINDOW:])\n",
    "    pred = model.predict([lastbatch.reshape(1,22, 5)])\n",
    "    pred =  np.array(y_scaler.inverse_transform(pred)) # predicted value\n",
    "\n",
    "    # now we make dataframe and create row names in date\n",
    "\n",
    "    splitStr = str(df.date_time[df.last_valid_index()]).split(' ')\n",
    "    lastDate =splitStr[0].split('-')\n",
    "    lastTime = splitStr[1].split(':')\n",
    "\n",
    "    predictionDate = datetime.datetime(int(lastDate[0]),int(lastDate[1]),int(lastDate[2]),\\\n",
    "                                    int(lastTime[0]), int(lastTime[1]))  + datetime.timedelta(minutes=5)\n",
    "\n",
    "    predictionDate = pd.date_range(predictionDate, periods=1)\n",
    "\n",
    "    prediction = pd.DataFrame(pred, columns=[\"predictionPrice\"], index = predictionDate.values)\n",
    "\n",
    "    print (prediction)\n",
    "\n",
    "    if plotForTrain:\n",
    "        \n",
    "        trainPredict = model.predict(X_train)\n",
    "        trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "        prices = df.close.values.astype('float32')\n",
    "        prices = prices.reshape(len(prices), 1)\n",
    "        trainPredictPlot = np.empty_like(prices)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "        Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.index).close\n",
    "        Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "        ActualValues = go.Scatter( x = df.date_time, y = Actual, name = 'ActualValues')\n",
    "        TrainingValues = go.Scatter( x = df.date_time, y = Training, name = 'TrainingValues')\n",
    "\n",
    "        iplot([ActualValues,TrainingValues])\n",
    "        plt.show()\n",
    "        \n",
    "    if plot:\n",
    "        trainPredict = model.predict(X_train)\n",
    "        testPredict = model.predict(X_test)\n",
    "\n",
    "        trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "        trainY = y_scaler.inverse_transform([y_train])\n",
    "\n",
    "        testPredict = y_scaler.inverse_transform(testPredict)\n",
    "        testY = y_scaler.inverse_transform([y_test])\n",
    "\n",
    "        trainScore = metrics.mean_squared_error(trainY[0], trainPredict[:,0]) ** .5\n",
    "        print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "        testScore = metrics.mean_squared_error(testY[0], testPredict[:,0]) ** .5\n",
    "        print('Test Score: %.2f RMSE' % (testScore))\n",
    "        prices = df.close.values.astype('float32')\n",
    "        prices = prices.reshape(len(prices), 1)\n",
    "        trainPredictPlot = np.empty_like(prices)\n",
    "        trainPredictPlot[:, :] = np.nan\n",
    "        trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "\n",
    "        testPredictPlot = np.empty_like(prices)\n",
    "        testPredictPlot[:, :] = np.nan\n",
    "        testPredictPlot[(len(prices) - testPredict.shape[0]):len(prices), :] = testPredict\n",
    "\n",
    "        plt.plot(pd.DataFrame(prices, columns=[\"close\"]).close, label='Actual')\n",
    "        plt.plot(pd.DataFrame(trainPredictPlot, columns=[\"close\"]).close, label='Training')\n",
    "        plt.plot(pd.DataFrame(testPredictPlot, columns=[\"close\"]).close, label='Testing')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "        interactiveGrapth = 1\n",
    "        if interactiveGrapth:\n",
    "\n",
    "            Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.index).close\n",
    "            Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "            Testing = pd.DataFrame(testPredictPlot, columns=[\"close\"], index=df.date_time).close\n",
    "\n",
    "            Actual.to_csv('Actual.csv')\n",
    "            Training.to_csv('Training.csv')\n",
    "            Testing.to_csv('Testing.csv')\n",
    "\n",
    "            #ActualValues = go.Scatter( x = df.date_time, y = Actual, name = 'ActualValues')\n",
    "            #TrainingValues = go.Scatter( x = df.date_time, y = Training, name = 'TrainingValues')\n",
    "            #TestingValues = go.Scatter( x = df.date_time, y = Testing, name = 'PredictedValues')\n",
    "\n",
    "            #iplot([ActualValues,TrainingValues, TestingValues])\n",
    "            #plt.show()\n",
    "        if plotHictory:\n",
    "\n",
    "            plt.plot(history.history['loss'], label = 'TrainLoss')\n",
    "            plt.plot(history.history['val_loss'], label = 'TestLoss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning:\n",
      "\n",
      "pd.ewm_mean is deprecated for DataFrame and will be removed in a future version, replace with \n",
      "\tDataFrame.ewm(com=2,min_periods=0,adjust=True,ignore_na=False).mean()\n",
      "\n",
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning:\n",
      "\n",
      "pd.ewm_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.ewm(com=2,min_periods=0,adjust=True,ignore_na=False).mean()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START FIT MODEL...\n",
      "Train on 186081 samples, validate on 20676 samples\n",
      "Epoch 1/200\n",
      "186081/186081 [==============================] - 232s - loss: 1.3766e-04 - acc: 5.3740e-06 - val_loss: 0.0019 - val_acc: 4.8365e-05\n",
      "Epoch 2/200\n",
      "186081/186081 [==============================] - 232s - loss: 5.4492e-05 - acc: 5.3740e-06 - val_loss: 0.0041 - val_acc: 4.8365e-05\n",
      "Epoch 3/200\n",
      "186081/186081 [==============================] - 232s - loss: 3.8855e-05 - acc: 5.3740e-06 - val_loss: 0.0061 - val_acc: 4.8365e-05\n",
      "Epoch 4/200\n",
      "186081/186081 [==============================] - 232s - loss: 3.3424e-05 - acc: 5.3740e-06 - val_loss: 0.0089 - val_acc: 4.8365e-05\n",
      "Epoch 5/200\n",
      "186081/186081 [==============================] - 241s - loss: 2.6421e-05 - acc: 5.3740e-06 - val_loss: 0.0025 - val_acc: 4.8365e-05\n",
      "Epoch 6/200\n",
      "186081/186081 [==============================] - 258s - loss: 1.9460e-05 - acc: 5.3740e-06 - val_loss: 0.0037 - val_acc: 4.8365e-05\n",
      "Epoch 7/200\n",
      "186081/186081 [==============================] - 248s - loss: 1.6946e-05 - acc: 5.3740e-06 - val_loss: 0.0042 - val_acc: 4.8365e-05\n",
      "Epoch 8/200\n",
      "186081/186081 [==============================] - 263s - loss: 1.5547e-05 - acc: 5.3740e-06 - val_loss: 0.0173 - val_acc: 4.8365e-05\n",
      "Epoch 9/200\n",
      "186081/186081 [==============================] - 263s - loss: 1.4908e-05 - acc: 5.3740e-06 - val_loss: 0.0073 - val_acc: 4.8365e-05\n",
      "Epoch 10/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.3247e-05 - acc: 5.3740e-06 - val_loss: 0.0149 - val_acc: 4.8365e-05\n",
      "Epoch 11/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.2129e-05 - acc: 5.3740e-06 - val_loss: 0.0113 - val_acc: 4.8365e-05\n",
      "Epoch 12/200\n",
      "186081/186081 [==============================] - 235s - loss: 1.1004e-05 - acc: 5.3740e-06 - val_loss: 0.0071 - val_acc: 4.8365e-05\n",
      "Epoch 13/200\n",
      "186081/186081 [==============================] - 234s - loss: 1.0148e-05 - acc: 5.3740e-06 - val_loss: 0.0121 - val_acc: 4.8365e-05\n",
      "Epoch 14/200\n",
      "186081/186081 [==============================] - 235s - loss: 9.8585e-06 - acc: 5.3740e-06 - val_loss: 0.0135 - val_acc: 4.8365e-05\n",
      "Epoch 15/200\n",
      "186081/186081 [==============================] - 236s - loss: 9.3775e-06 - acc: 5.3740e-06 - val_loss: 0.0106 - val_acc: 4.8365e-05\n",
      "Epoch 16/200\n",
      "186081/186081 [==============================] - 235s - loss: 8.9064e-06 - acc: 5.3740e-06 - val_loss: 0.0105 - val_acc: 4.8365e-05\n",
      "Epoch 17/200\n",
      "186081/186081 [==============================] - 234s - loss: 8.3041e-06 - acc: 5.3740e-06 - val_loss: 0.0106 - val_acc: 4.8365e-05\n",
      "Epoch 18/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.9790e-06 - acc: 5.3740e-06 - val_loss: 0.0108 - val_acc: 4.8365e-05\n",
      "Epoch 19/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.4972e-06 - acc: 5.3740e-06 - val_loss: 0.0107 - val_acc: 4.8365e-05\n",
      "Epoch 20/200\n",
      "186081/186081 [==============================] - 234s - loss: 7.1531e-06 - acc: 5.3740e-06 - val_loss: 0.0120 - val_acc: 4.8365e-05\n",
      "Epoch 21/200\n",
      "186081/186081 [==============================] - 235s - loss: 6.9927e-06 - acc: 5.3740e-06 - val_loss: 0.0094 - val_acc: 4.8365e-05\n",
      "Epoch 22/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.6654e-06 - acc: 5.3740e-06 - val_loss: 0.0122 - val_acc: 4.8365e-05\n",
      "Epoch 23/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.5135e-06 - acc: 5.3740e-06 - val_loss: 0.0163 - val_acc: 4.8365e-05\n",
      "Epoch 24/200\n",
      "186081/186081 [==============================] - 236s - loss: 6.3315e-06 - acc: 5.3740e-06 - val_loss: 0.0143 - val_acc: 4.8365e-05\n",
      "Epoch 25/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.3030e-06 - acc: 5.3740e-06 - val_loss: 0.0183 - val_acc: 4.8365e-05\n",
      "Epoch 26/200\n",
      "186081/186081 [==============================] - 234s - loss: 6.0133e-06 - acc: 5.3740e-06 - val_loss: 0.0168 - val_acc: 4.8365e-05\n",
      "Epoch 27/200\n",
      "186081/186081 [==============================] - 235s - loss: 5.8277e-06 - acc: 5.3740e-06 - val_loss: 0.0203 - val_acc: 4.8365e-05\n",
      "Epoch 28/200\n",
      "186081/186081 [==============================] - 234s - loss: 5.5078e-06 - acc: 5.3740e-06 - val_loss: 0.0199 - val_acc: 4.8365e-05\n",
      "Epoch 29/200\n",
      "186081/186081 [==============================] - 234s - loss: 5.3238e-06 - acc: 5.3740e-06 - val_loss: 0.0218 - val_acc: 4.8365e-05\n",
      "Epoch 30/200\n",
      "186081/186081 [==============================] - 234s - loss: 5.2869e-06 - acc: 5.3740e-06 - val_loss: 0.0248 - val_acc: 4.8365e-05\n",
      "Epoch 31/200\n",
      "186081/186081 [==============================] - 234s - loss: 5.0309e-06 - acc: 5.3740e-06 - val_loss: 0.0239 - val_acc: 4.8365e-05\n",
      "Epoch 32/200\n",
      "186081/186081 [==============================] - 234s - loss: 5.0524e-06 - acc: 5.3740e-06 - val_loss: 0.0198 - val_acc: 4.8365e-05\n",
      "Epoch 33/200\n",
      "186081/186081 [==============================] - 234s - loss: 4.8690e-06 - acc: 5.3740e-06 - val_loss: 0.0200 - val_acc: 4.8365e-05\n",
      "Epoch 34/200\n",
      "186081/186081 [==============================] - 237s - loss: 4.7374e-06 - acc: 5.3740e-06 - val_loss: 0.0234 - val_acc: 4.8365e-05\n",
      "Epoch 35/200\n",
      "186081/186081 [==============================] - 235s - loss: 4.6817e-06 - acc: 5.3740e-06 - val_loss: 0.0224 - val_acc: 4.8365e-05\n",
      "Epoch 36/200\n",
      "186081/186081 [==============================] - 234s - loss: 4.5043e-06 - acc: 5.3740e-06 - val_loss: 0.0179 - val_acc: 4.8365e-05\n",
      "Epoch 37/200\n",
      "  2400/186081 [..............................] - ETA: 225s - loss: 3.0778e-06 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-d32398da5126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUSDT_BTC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext5minutePrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'USDT_BTC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'poloniex'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-ef7967beaefa>\u001b[0m in \u001b[0;36mnext5minutePrediction\u001b[0;34m(typeBlockchain, stock)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     history= model.fit(X_train, y_train, validation_data=(X_test, y_test),  batch_size=32, epochs=200,verbose=1,\n\u001b[0;32m---> 44\u001b[0;31m               callbacks=[history])\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m--> 984\u001b[0;31m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0mfetch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;34m\"\"\"The string name of this tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation was not named: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"%s:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;34m\"\"\"The full name of this operation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "USDT_BTC = next5minutePrediction('USDT_BTC', 'poloniex' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
