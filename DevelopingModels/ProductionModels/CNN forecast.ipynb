{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.get_data as get_data\n",
    "import src.load_data as load\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "from keras.callbacks import History \n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.layers import  Flatten, Convolution1D, MaxPooling1D\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "WINDOW = 22\n",
    "\n",
    "# LITERATURE:\n",
    "# [1] http://cs231n.stanford.edu/reports/2015/pdfs/ashwin_final_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape):\n",
    "    d = 0.2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(input_shape = input_shape, \n",
    "                            nb_filter=128,\n",
    "                            filter_length=2,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))    \n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "    model.add(Convolution1D(input_shape = input_shape, \n",
    "                            nb_filter=128,\n",
    "                            filter_length=2,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_data.get_data_frame()\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "all_df = df.copy()\n",
    "\n",
    "x = all_df[['open', 'low', 'high', 'volume']].copy()\n",
    "\n",
    "y = all_df['close'].copy()\n",
    "n_features = x.shape[1]\n",
    "\n",
    "#x = pd.ewma(x,2)\n",
    "#y = pd.ewma(y,2)\n",
    "x[['open', 'low', 'high', 'volume']] = x_scaler.fit_transform(x)\n",
    "\n",
    "y = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "x['close'] = y\n",
    "\n",
    "#X_train, y_train = load.load_data(x, WINDOW, TrainTest = False)\n",
    "X_train, y_train, X_test, y_test = load.load_data(x, WINDOW, train_size= 0.9, TrainTest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(22, 4), activation=\"relu\", filters=128, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "\n",
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning:\n",
      "\n",
      "Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "\n",
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning:\n",
      "\n",
      "Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(22, 4), activation=\"relu\", filters=128, kernel_size=2, strides=1, padding=\"valid\")`\n",
      "\n",
      "/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning:\n",
      "\n",
      "Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START FIT MODEL...\n",
      "Train on 637 samples, validate on 71 samples\n",
      "Epoch 1/10\n",
      "637/637 [==============================] - 0s - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0141\n",
      "Epoch 2/10\n",
      "637/637 [==============================] - 0s - loss: 9.5275e-04 - acc: 0.0000e+00 - val_loss: 0.0100 - val_acc: 0.0141\n",
      "Epoch 3/10\n",
      "637/637 [==============================] - 0s - loss: 6.9410e-04 - acc: 0.0000e+00 - val_loss: 0.0105 - val_acc: 0.0141\n",
      "Epoch 4/10\n",
      "637/637 [==============================] - 0s - loss: 7.4330e-04 - acc: 0.0000e+00 - val_loss: 0.0166 - val_acc: 0.0141\n",
      "Epoch 5/10\n",
      "637/637 [==============================] - 0s - loss: 6.7232e-04 - acc: 0.0000e+00 - val_loss: 0.0094 - val_acc: 0.0141\n",
      "Epoch 6/10\n",
      "637/637 [==============================] - 0s - loss: 6.5805e-04 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0141\n",
      "Epoch 7/10\n",
      "637/637 [==============================] - 0s - loss: 7.3573e-04 - acc: 0.0000e+00 - val_loss: 0.0130 - val_acc: 0.0141\n",
      "Epoch 8/10\n",
      "637/637 [==============================] - 0s - loss: 7.1062e-04 - acc: 0.0000e+00 - val_loss: 0.0158 - val_acc: 0.0141\n",
      "Epoch 9/10\n",
      "637/637 [==============================] - 0s - loss: 6.4784e-04 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0141\n",
      "Epoch 10/10\n",
      "637/637 [==============================] - 0s - loss: 7.4604e-04 - acc: 0.0000e+00 - val_loss: 0.0084 - val_acc: 0.0141\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "model = build_model(input_shape=(WINDOW, n_features))\n",
    "\n",
    "print('START FIT MODEL...')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "history = History()\n",
    "history= model.fit(X_train, y_train, validation_data=(X_test, y_test),  batch_size=32, epochs=10,verbose=1,\n",
    "          callbacks=[history])\n",
    "\n",
    "end = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning time:  0.9288733005523682\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv1d_5_input to have shape (None, 22, 4) but got array with shape (1, 22, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-97c121e1c7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# one day prediction. get last batch known data (now we didnt need in y value and can predict it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlastbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mWINDOW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlastbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predicted value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv1d_5_input to have shape (None, 22, 4) but got array with shape (1, 22, 5)"
     ]
    }
   ],
   "source": [
    "print ('Learning time: ', end-start)\n",
    "\n",
    "today = time.strftime(\"_%d_%m_%Y\")\n",
    "\n",
    "#pathModel = \"../../models/model_5f_\" + typeBlockchain + today +\".h5\"\n",
    "#save_model(model, pathModel)\n",
    "#model = load_model(pathModel)\n",
    "# one day prediction. get last batch known data (now we didnt need in y value and can predict it)    \n",
    "lastbatch = np.array(x[-WINDOW:])\n",
    "pred = model.predict([lastbatch.reshape(1,22, 5)])\n",
    "pred =  np.array(y_scaler.inverse_transform(pred)) # predicted value\n",
    "\n",
    "# now we make dataframe and create row names in date\n",
    "\n",
    "lastDate =str(df.date[df.last_valid_index()]).split('-')\n",
    "currentData = datetime.date(int(lastDate[0]),int(lastDate[1]),int(lastDate[2])) + datetime.timedelta(1)\n",
    "predictionDate = pd.date_range(currentData, periods=1)\n",
    "prediction = pd.DataFrame(pred, columns=[\"predictionPrice\"], index = predictionDate.values)\n",
    "\n",
    "print (prediction)\n",
    "\n",
    "\n",
    "plot = 1\n",
    "plotHictory = 1\n",
    "if plot:\n",
    "    trainPredict = model.predict(X_train)\n",
    "    testPredict = model.predict(X_test)\n",
    "\n",
    "    trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "    trainY = y_scaler.inverse_transform([y_train])\n",
    "\n",
    "    testPredict = y_scaler.inverse_transform(testPredict)\n",
    "    testY = y_scaler.inverse_transform([y_test])\n",
    "\n",
    "    trainScore = metrics.mean_squared_error(trainY[0], trainPredict[:,0]) ** .5\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "    testScore = metrics.mean_squared_error(testY[0], testPredict[:,0]) ** .5\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    prices = df.close.values.astype('float32')\n",
    "    prices = prices.reshape(len(prices), 1)\n",
    "    trainPredictPlot = np.empty_like(prices)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(prices)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[(len(prices) - testPredict.shape[0]):len(prices), :] = testPredict\n",
    "\n",
    "    plt.plot(pd.DataFrame(prices, columns=[\"close\"], index=df.index).close, label='Actual')\n",
    "    plt.plot(pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.index).close, label='Training')\n",
    "    plt.plot(pd.DataFrame(testPredictPlot, columns=[\"close\"], index=df.index).close, label='Testing')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    interactiveGrapth = 1\n",
    "    if interactiveGrapth:\n",
    "\n",
    "        Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.index).close\n",
    "        Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date).close\n",
    "        Testing = pd.DataFrame(testPredictPlot, columns=[\"close\"], index=df.date).close\n",
    "\n",
    "        ActualValues = go.Scatter( x = df.date, y = Actual, name = 'ActualValues')\n",
    "        TrainingValues = go.Scatter( x = df.date, y = Training, name = 'TrainingValues')\n",
    "        TestingValues = go.Scatter( x = df.date, y = Testing, name = 'PredictedValues')\n",
    "\n",
    "        iplot([ActualValues,TrainingValues, TestingValues])\n",
    "        plt.show()\n",
    "\n",
    "    if plotHictory:\n",
    "\n",
    "        plt.plot(history.history['loss'], label = 'TrainLoss')\n",
    "        plt.plot(history.history['val_loss'], label = 'TestLoss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
