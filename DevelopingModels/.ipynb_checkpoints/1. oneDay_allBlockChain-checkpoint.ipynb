{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "import datetime \n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import time\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "WINDOW = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Парсинг данных\n",
    "\n",
    "\"\"\"\n",
    "def connect(user, password, db, host: str, port: int, echo=True):\n",
    "    url = 'postgresql+psycopg2://{}:{}@{}:{}/{}'\n",
    "    url = url.format(user, password, host, port, db)\n",
    "    eng = sqlalchemy.create_engine(url, client_encoding='utf8', echo=echo)\n",
    "    meta = sqlalchemy.MetaData(bind=eng)\n",
    "\n",
    "    return eng, meta\n",
    "\n",
    "\n",
    "def get_data_frame(pair: str = 'USDT_BTC', exchange: str = 'poloniex') -> pd.DataFrame:\n",
    "    \"\"\"Метод стягивания данных из базы в датафрейм.\n",
    "    По умолчанию тянет все значения в базе для валютной пары доллар биткоин.\n",
    "    Список спаршенных пар смотри в таблице Pair\n",
    "    Цепляться будет отовсюду где есть инетрнет\"\"\"\n",
    "    engine, meta = connect(user='postgres', password='password', db='btccandles', host='94.230.125.199', port=16432)\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT date, time, open, close, low, high, volume, pair.\\\"name\\\"\"\n",
    "        \"FROM candlestick, pair WHERE candlestick.pair_id = pair.id AND pair.id IN (\"\n",
    "        \"SELECT pair.id FROM pair, exchange WHERE (\"\n",
    "        \"SELECT pair.id FROM pair WHERE pair.name = '\" + pair +\n",
    "        \"') = pair.alias_id AND pair.exchange_id = (SELECT exchange.id FROM exchange WHERE exchange.\\\"name\\\" = '\" + exchange + \"'));\",\n",
    "        con=engine)\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Загрузка данных\n",
    "\"\"\"\n",
    "def load_data(X, seq_len, train_size=1):\n",
    "    # Определяем число фич\n",
    "    amount_of_features = X.shape[1] \n",
    "    \n",
    "    sequence_length = seq_len + 1 \n",
    "    data = []\n",
    "    \n",
    "    # Бьем тренировочные данные на блоки по размеру окна\n",
    "    for index in range(len(X) - sequence_length):\n",
    "        data.append(X[index: index + sequence_length])\n",
    "    \n",
    "    data = np.array(data)\n",
    "    train_split = int(round(train_size * data.shape[0]))\n",
    "    train_data = data[:train_split, :]\n",
    "    \n",
    "    x_train = train_data[:, :-1]\n",
    "    y_train = train_data[:, -1][:,-1]\n",
    "    \n",
    "    # Меняем размер входного фрейма на [dim, window, featureNumber]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    return x_train, y_train\n",
    "\n",
    "\"\"\"\n",
    "Собираем LSTM\n",
    "\"\"\"\n",
    "\n",
    "def build_model(input_shape):\n",
    "    d = 0.2\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"normal\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"normal\",activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predictNumDay(num, pathModel, data, scaler):\n",
    "    m = load_model(pathModel)\n",
    "    \n",
    "    prediction = []\n",
    "    lastbatch = (data[-WINDOW:])\n",
    "    for i in np.arange(num):    \n",
    "        res = m.predict([lastbatch.reshape(1,22, 1)])\n",
    "        prediction.append(scaler.inverse_transform(res))\n",
    "        lastbatch = np.concatenate([lastbatch[1:],res])\n",
    "        m.train_on_batch(lastbatch.reshape(1,22,1), res)\n",
    "           \n",
    "    return np.array(prediction).reshape(num)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "typeBlockchain:\n",
    "USDT_BTC\n",
    "USDT_LTC\n",
    "USDT_ETH\n",
    "USDT_ETC\n",
    "USDT_XRP\n",
    "\"\"\"\n",
    "\n",
    "def nextDayPrediction(typeBlockchain, N = 1):    \n",
    "    \n",
    "    df = get_data_frame(typeBlockchain)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "    x = df['close'].copy()\n",
    "    y = df['close'].copy()\n",
    "\n",
    "    x = scaler.fit_transform(x.values.reshape(-1, 1))\n",
    "\n",
    "    y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "    \n",
    "    X_train, y_train = load_data(x, WINDOW)\n",
    "    \n",
    "    #print (X_train.shape, y_train.shape)\n",
    "    \n",
    "    model = build_model(input_shape=(WINDOW, 1))\n",
    "    \n",
    "    print('START FIT MODEL...')\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=500,verbose=0)\n",
    "    end = time.time()\n",
    "\n",
    "    print ('Learning time: ', end-start)\n",
    "    \n",
    "    today = time.strftime(\"_%d_%m_%Y\")\n",
    "    \n",
    "    pathModel = \"../models/model_1f_\" + typeBlockchain + today +\".h5\"\n",
    "    save_model(model, pathModel)\n",
    "    \n",
    "    #model = load_model(pathModel)\n",
    "    \n",
    "    trainPredict = model.predict(X_train)\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([y_train])\n",
    "\n",
    "    trainScore = metrics.mean_squared_error(trainY[0], trainPredict[:,0]) ** .5\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    \n",
    "    prices = df.close.values.astype('float32')\n",
    "    prices = prices.reshape(len(prices), 1)\n",
    "    \n",
    "    trainPredictPlot = np.empty_like(prices)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[WINDOW:len(trainPredict)+WINDOW, :] = trainPredict\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(pd.DataFrame(prices, columns=[\"close\"], index=df.index).close, label='Actual')\n",
    "    plt.plot(pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.index).close, label='Training')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lastDate =str(df.date[df.last_valid_index()]).split('-')\n",
    "    currentData = datetime.date(int(lastDate[0]),int(lastDate[1]),int(lastDate[2])+1)\n",
    "    predictionDate = pd.date_range(currentData,periods=N)\n",
    "    predictNday =  (predictNumDay(N, pathModel, x, scaler))\n",
    "\n",
    "    prediction = pd.DataFrame(predictNday, columns=[\"predictionPrice\"], index = predictionDate.values)\n",
    "    \n",
    "    Actual = pd.DataFrame(prices, columns=[\"close\"], index=df.date).close\n",
    "    Training = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date).close\n",
    "    pred = pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=df.date).close\n",
    "\n",
    "    \"\"\"ActualValues = go.Scatter( x = df.date, y = Actual, name = 'ActualValues')\n",
    "    TrainingValues = go.Scatter( x = df.date, y = Training, name = 'TrainingValues')\n",
    "\n",
    "    iplot([ActualValues,TrainingValues])\n",
    "    \n",
    "    our_Predict = go.Scatter( x = prediction.index, y = prediction.predictionPrice, name = 'Next5DayValues')\n",
    "\n",
    "    iplot([our_Predict, ActualValues])\"\"\"\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-20 21:46:42,975 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2017-07-20 21:46:42,976 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 21:46:42,978 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2017-07-20 21:46:42,979 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 21:46:42,981 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 21:46:42,982 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 21:46:42,983 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 21:46:42,984 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 21:46:42,985 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2017-07-20 21:46:42,987 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 21:46:42,988 INFO sqlalchemy.engine.base.Engine select date, time, open, close, low, high, volume, pair.\"name\" from candlestick, pair where candlestick.pair_id=pair.id and pair.\"name\"='USDT_BTC';\n",
      "2017-07-20 21:46:42,989 INFO sqlalchemy.engine.base.Engine {}\n",
      "START FIT MODEL...\n",
      "Learning time:  456.6240327358246\n",
      "Train Score: 67.20 RMSE\n"
     ]
    }
   ],
   "source": [
    "USDT_BTC = nextDayPrediction('USDT_BTC', N = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-20 22:03:44,632 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2017-07-20 22:03:44,633 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:03:44,634 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2017-07-20 22:03:44,635 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:03:44,636 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:03:44,637 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:03:44,638 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:03:44,639 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:03:44,640 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2017-07-20 22:03:44,640 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:03:44,642 INFO sqlalchemy.engine.base.Engine select date, time, open, close, low, high, volume, pair.\"name\" from candlestick, pair where candlestick.pair_id=pair.id and pair.\"name\"='USDT_LTC';\n",
      "2017-07-20 22:03:44,642 INFO sqlalchemy.engine.base.Engine {}\n",
      "START FIT MODEL...\n",
      "Learning time:  466.21084475517273\n",
      "Train Score: 1.09 RMSE\n"
     ]
    }
   ],
   "source": [
    "USDT_LTC = nextDayPrediction('USDT_LTC', N = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-20 22:14:09,693 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2017-07-20 22:14:09,694 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:14:09,698 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2017-07-20 22:14:09,698 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:14:09,701 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:14:09,702 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:14:09,703 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:14:09,704 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:14:09,705 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2017-07-20 22:14:09,705 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:14:09,707 INFO sqlalchemy.engine.base.Engine select date, time, open, close, low, high, volume, pair.\"name\" from candlestick, pair where candlestick.pair_id=pair.id and pair.\"name\"='USDT_ETH';\n",
      "2017-07-20 22:14:09,707 INFO sqlalchemy.engine.base.Engine {}\n",
      "START FIT MODEL...\n",
      "Learning time:  458.9413049221039\n",
      "Train Score: 4.47 RMSE\n"
     ]
    }
   ],
   "source": [
    "USDT_ETH = nextDayPrediction('USDT_ETH', N = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-20 22:35:07,242 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2017-07-20 22:35:07,242 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:35:07,244 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2017-07-20 22:35:07,244 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:35:07,246 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:35:07,246 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:35:07,248 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:35:07,248 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:35:07,250 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2017-07-20 22:35:07,250 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:35:07,251 INFO sqlalchemy.engine.base.Engine select date, time, open, close, low, high, volume, pair.\"name\" from candlestick, pair where candlestick.pair_id=pair.id and pair.\"name\"='USDT_ETC';\n",
      "2017-07-20 22:35:07,252 INFO sqlalchemy.engine.base.Engine {}\n",
      "START FIT MODEL...\n",
      "Learning time:  301.99461221694946\n",
      "Train Score: 0.55 RMSE\n"
     ]
    }
   ],
   "source": [
    "USDT_ETC = nextDayPrediction('USDT_ETC', N = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-20 22:59:06,587 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2017-07-20 22:59:06,588 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:59:06,590 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2017-07-20 22:59:06,590 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:59:06,592 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:59:06,593 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:59:06,595 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2017-07-20 22:59:06,595 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:59:06,597 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2017-07-20 22:59:06,598 INFO sqlalchemy.engine.base.Engine {}\n",
      "2017-07-20 22:59:06,599 INFO sqlalchemy.engine.base.Engine select date, time, open, close, low, high, volume, pair.\"name\" from candlestick, pair where candlestick.pair_id=pair.id and pair.\"name\"='USDT_XRP';\n",
      "2017-07-20 22:59:06,600 INFO sqlalchemy.engine.base.Engine {}\n",
      "START FIT MODEL...\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,128]\n\t [[Node: gradients_9/lstm_12/while/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@lstm_12/while/MatMul\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_9/lstm_12/while/MatMul_grad/MatMul_1/StackPop, gradients_9/lstm_12/while/add_grad/Reshape_1)]]\n\nCaused by op 'gradients_9/lstm_12/while/MatMul_grad/MatMul_1', defined at:\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-90d0800187c4>\", line 1, in <module>\n    USDT_XRP = nextDayPrediction('USDT_XRP', N = 1)\n  File \"<ipython-input-3-20efa39edcbb>\", line 33, in nextDayPrediction\n    model.fit(X_train, y_train, batch_size=32, epochs=500,verbose=0)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/models.py\", line 845, in fit\n    initial_epoch=initial_epoch)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 1457, in fit\n    self._make_train_function()\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 1001, in _make_train_function\n    self.total_loss)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/optimizers.py\", line 381, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2108, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 825, in _MatMulGrad\n    grad_b = math_ops.matmul(a, grad, transpose_a=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'lstm_12/while/MatMul', defined at:\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-9-90d0800187c4>\", line 1, in <module>\n    USDT_XRP = nextDayPrediction('USDT_XRP', N = 1)\n  File \"<ipython-input-3-20efa39edcbb>\", line 28, in nextDayPrediction\n    model = build_model(input_shape=(WINDOW, 1))\n  File \"<ipython-input-2-5c5b83b019be>\", line 62, in build_model\n    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/models.py\", line 455, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 252, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 554, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 298, in call\n    input_length=input_shape[1])\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2339, in rnn\n    swap_memory=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2328, in _step\n    tuple(constants))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 1105, in step\n    self.recurrent_kernel_i))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 846, in dot\n    out = tf.matmul(x, y)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,128]\n\t [[Node: gradients_9/lstm_12/while/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@lstm_12/while/MatMul\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_9/lstm_12/while/MatMul_grad/MatMul_1/StackPop, gradients_9/lstm_12/while/add_grad/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,128]\n\t [[Node: gradients_9/lstm_12/while/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@lstm_12/while/MatMul\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_9/lstm_12/while/MatMul_grad/MatMul_1/StackPop, gradients_9/lstm_12/while/add_grad/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-90d0800187c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUSDT_XRP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextDayPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'USDT_XRP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-20efa39edcbb>\u001b[0m in \u001b[0;36mnextDayPrediction\u001b[0;34m(typeBlockchain, N)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/root/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,128]\n\t [[Node: gradients_9/lstm_12/while/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@lstm_12/while/MatMul\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_9/lstm_12/while/MatMul_grad/MatMul_1/StackPop, gradients_9/lstm_12/while/add_grad/Reshape_1)]]\n\nCaused by op 'gradients_9/lstm_12/while/MatMul_grad/MatMul_1', defined at:\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-90d0800187c4>\", line 1, in <module>\n    USDT_XRP = nextDayPrediction('USDT_XRP', N = 1)\n  File \"<ipython-input-3-20efa39edcbb>\", line 33, in nextDayPrediction\n    model.fit(X_train, y_train, batch_size=32, epochs=500,verbose=0)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/models.py\", line 845, in fit\n    initial_epoch=initial_epoch)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 1457, in fit\n    self._make_train_function()\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/training.py\", line 1001, in _make_train_function\n    self.total_loss)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/optimizers.py\", line 381, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/optimizers.py\", line 47, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2108, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 825, in _MatMulGrad\n    grad_b = math_ops.matmul(a, grad, transpose_a=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'lstm_12/while/MatMul', defined at:\n  File \"/root/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-9-90d0800187c4>\", line 1, in <module>\n    USDT_XRP = nextDayPrediction('USDT_XRP', N = 1)\n  File \"<ipython-input-3-20efa39edcbb>\", line 28, in nextDayPrediction\n    model = build_model(input_shape=(WINDOW, 1))\n  File \"<ipython-input-2-5c5b83b019be>\", line 62, in build_model\n    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/models.py\", line 455, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 252, in __call__\n    return super(Recurrent, self).__call__(inputs, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 554, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 298, in call\n    input_length=input_shape[1])\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2339, in rnn\n    swap_memory=True)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2328, in _step\n    tuple(constants))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\", line 1105, in step\n    self.recurrent_kernel_i))\n  File \"/root/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 846, in dot\n    out = tf.matmul(x, y)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,128]\n\t [[Node: gradients_9/lstm_12/while/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@lstm_12/while/MatMul\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_9/lstm_12/while/MatMul_grad/MatMul_1/StackPop, gradients_9/lstm_12/while/add_grad/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "USDT_XRP = nextDayPrediction('USDT_XRP', N = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDT_BTC:\n",
      "             predictionPrice\n",
      "2017-07-21      2250.067871\n",
      "USDT_LTC:\n",
      "             predictionPrice\n",
      "2017-07-21        42.998005\n",
      "USDT_ETH:\n",
      "             predictionPrice\n",
      "2017-07-21       198.491074\n",
      "USDT_ETC:\n",
      "             predictionPrice\n",
      "2017-07-21        16.313128\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'USDT_XRP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9a09c03f2c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'USDT_ETH:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSDT_ETH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'USDT_ETC:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSDT_ETC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'USDT_XRP:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSDT_XRP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'USDT_XRP' is not defined"
     ]
    }
   ],
   "source": [
    "print ('USDT_BTC:\\n', USDT_BTC)\n",
    "print ('USDT_LTC:\\n', USDT_LTC)\n",
    "print ('USDT_ETH:\\n', USDT_ETH)\n",
    "print ('USDT_ETC:\\n', USDT_ETC)\n",
    "print ('USDT_XRP:\\n', USDT_XRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
